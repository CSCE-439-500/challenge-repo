# AI Provider Configuration
# Choose between "gemini" and "openai"
AI_PROVIDER=gemini

# Model ID - leave empty to use default model for the selected provider
# Gemini defaults: gemini-2.0-flash-lite, gemini-2.5-flash-previev
# OpenAI defaults: gpt-5o
AI_MODEL_ID=gemini-2.0-flash-lite

# API Configuration
OPENAI_API_KEY=
GEMINI_API_KEY=

# Optional: OpenAI Organization ID
# OPENAI_ORG_ID=your_org_id_here

RUST_CRYPTER_PATH=/rust/crypt/path/here

# --- Local Model API ---
# URL for the locally running model API (single model on port 8080)
MODEL_API_URL=http://127.0.0.1:8080
# Timeout in seconds for model API requests
MODEL_API_TIMEOUT=30

# --- Red-team Safety Toggles ---
# Enable guarded red-team mode (fail closed when not true)
REDTEAM_MODE=true
# Allow file/network actions (keep false for dry-run by default)
ALLOW_ACTIONS=true

# --- Determinism / Testing ---
# Fixed seed for deterministic behavior in tests/CI
RANDOM_SEED=42

# --- Network Allowlist (optional) ---
# Comma-separated host allowlist for egress when enabled
ALLOWED_HOSTS=127.0.0.1
